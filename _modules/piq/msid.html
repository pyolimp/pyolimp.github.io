<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>piq.msid &#8212; PyOlimp 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=1aa832ab" />
    <script src="../../_static/documentation_options.js?v=01f34227"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for piq.msid</h1><div class="highlight"><pre>
<span></span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Implementation of Multi-scale Evaluation metric, based on paper</span>
<span class="sd"> https://arxiv.org/abs/1905.11141 and author&#39;s repository https://github.com/xgfs/msid</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">piq.base</span> <span class="kn">import</span> <span class="n">BaseFeatureMetric</span>
<span class="kn">from</span> <span class="nn">piq.utils</span> <span class="kn">import</span> <span class="n">_validate_input</span><span class="p">,</span> <span class="n">_parse_version</span>


<span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">NORMALIZATION</span> <span class="o">=</span> <span class="mf">1e6</span>


<span class="k">def</span> <span class="nf">_np_euc_cdist</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">dd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">dist</span> <span class="o">+=</span> <span class="n">dd</span> <span class="o">+</span> <span class="n">dd</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span>


<span class="k">def</span> <span class="nf">_construct_graph_sparse</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">lil_matrix</span>
    <span class="n">spmat</span> <span class="o">=</span> <span class="n">lil_matrix</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">dd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">dd</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[:</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">inds</span> <span class="o">=</span> <span class="n">inds</span><span class="p">[</span><span class="n">inds</span> <span class="o">!=</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">spmat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">inds</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">spmat</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_laplacian_sparse</span><span class="p">(</span><span class="n">matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">diags</span><span class="p">,</span> <span class="n">eye</span>
    <span class="n">row_sum</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalized</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">diags</span><span class="p">(</span><span class="n">row_sum</span><span class="p">)</span> <span class="o">-</span> <span class="n">matrix</span>

    <span class="n">row_sum_sqrt</span> <span class="o">=</span> <span class="n">diags</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">row_sum</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">row_sum_sqrt</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">row_sum_sqrt</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_lanczos_m</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">nv</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">starting_vectors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> \
        <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Lanczos algorithm computes symmetric m x m tridiagonal matrix T and matrix V with orthogonal rows</span>
<span class="sd">        constituting the basis of the Krylov subspace K_m(A, x),</span>
<span class="sd">        where x is an arbitrary starting unit vector.</span>
<span class="sd">        This implementation parallelizes `nv` starting vectors.</span>

<span class="sd">    Args:</span>
<span class="sd">        A: matrix based on which the Krylov subspace will be built.</span>
<span class="sd">        m: Number of Lanczos steps.</span>
<span class="sd">        nv: Number of random vectors.</span>
<span class="sd">        rademacher: True to use Rademacher distribution,</span>
<span class="sd">            False - standard normal for random vectors</span>
<span class="sd">        starting_vectors: Specified starting vectors.</span>

<span class="sd">    Returns:</span>
<span class="sd">        T: Array with shape (nv, m, m), where T[i, :, :] is the i-th symmetric tridiagonal matrix.</span>
<span class="sd">        V: Array with shape (n, m, nv) where, V[:, :, i] is the i-th matrix with orthogonal rows.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">orthtol</span> <span class="o">=</span> <span class="mf">1e-5</span>
    <span class="k">if</span> <span class="n">starting_vectors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rademacher</span><span class="p">:</span>
            <span class="n">starting_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nv</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">starting_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nv</span><span class="p">)</span>  <span class="c1"># init random vectors in columns: n x nv</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">starting_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">m</span><span class="p">,</span> <span class="n">nv</span><span class="p">))</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nv</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>

    <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">starting_vectors</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">starting_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="n">starting_vectors</span><span class="p">)</span>  <span class="c1"># normalize each column</span>
    <span class="n">V</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">starting_vectors</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">starting_vectors</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ij-&gt;j&#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">starting_vectors</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">-=</span> <span class="n">alpha</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">starting_vectors</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ij-&gt;j&#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

    <span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
    <span class="n">T</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>

    <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">beta</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">out</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
    <span class="n">V</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">nv</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="n">old_starting_vectors</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">starting_vectors</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">starting_vectors</span><span class="p">)</span>  <span class="c1"># sparse @ dense</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="n">beta</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">old_starting_vectors</span>  <span class="c1"># n x nv</span>
        <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ij-&gt;j&#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">starting_vectors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">T</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">w</span> <span class="o">-=</span> <span class="n">alpha</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">starting_vectors</span>  <span class="c1"># n x nv</span>

            <span class="c1"># reortho</span>
            <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;jk&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,jk-&gt;ik&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ij-&gt;j&#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">beta</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">out</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>

            <span class="n">T</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
            <span class="n">T</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>

            <span class="c1"># more reotho</span>
            <span class="n">innerprod</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;jk&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
            <span class="n">reortho</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">innerprod</span> <span class="o">&gt;</span> <span class="n">orthtol</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                    <span class="n">reortho</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>

                <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;jk&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
                <span class="n">w</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,jk-&gt;ik&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
                <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">out</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">innerprod</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;jk&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

            <span class="n">V</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">w</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-6</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">reortho</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="k">return</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span>


<span class="k">def</span> <span class="nf">_slq</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the trace of matrix exponential</span>

<span class="sd">    Args:</span>
<span class="sd">        A: Square matrix in trace(exp(A)).</span>
<span class="sd">        m: Number of Lanczos steps.</span>
<span class="sd">        niters: Number of quadratures (also, the number of random vectors in the hutchinson trace estimator).</span>
<span class="sd">        rademacher: True to use Rademacher distribution,</span>
<span class="sd">            False - standard normal for random vectors in Hutchinson.</span>
<span class="sd">    Returns:</span>
<span class="sd">        trace: Estimate of trace of matrix exponential.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_lanczos_m</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">niters</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">)</span>
    <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">expeig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)</span>
    <span class="n">sqeigv1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">expeig</span> <span class="o">*</span> <span class="n">sqeigv1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">niters</span>
    <span class="k">return</span> <span class="n">trace</span>


<span class="k">def</span> <span class="nf">_slq_ts</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the trace of matrix exponential</span>

<span class="sd">    Args:</span>
<span class="sd">        A: Square matrix in trace(exp(-t*A)), where t is temperature</span>
<span class="sd">        m: Number of Lanczos steps.</span>
<span class="sd">        niters: Number of quadratures (also, the number of random vectors in the hutchinson trace estimator).</span>
<span class="sd">        ts: Array with temperatures.</span>
<span class="sd">        rademacher: True to use Rademacher distribution, False - standard normal for random vectors in Hutchinson</span>

<span class="sd">    Returns:</span>
<span class="sd">        trace: Estimate of trace of matrix exponential across temperatures `ts`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_lanczos_m</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">niters</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">)</span>
    <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">expeig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">eigvals</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">niters</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="n">sqeigv1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">expeig</span> <span class="o">*</span> <span class="n">sqeigv1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">traces</span>


<span class="k">def</span> <span class="nf">_slq_ts_fs</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">fs</span><span class="p">:</span> <span class="n">List</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the trace of matrix functions</span>

<span class="sd">    Args:</span>
<span class="sd">        A: Square matrix in trace(exp(-t*A)), where t is temperature.</span>
<span class="sd">        m: Number of Lanczos steps.</span>
<span class="sd">        niters: Number of quadratures (also, the number of random vectors in the hutchinson trace estimator).</span>
<span class="sd">        ts: Array with temperatures.</span>
<span class="sd">        rademacher: True to use Rademacher distribution, else - standard normal for random vectors in Hutchinson</span>
<span class="sd">        fs: A list of functions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        traces: Estimate of traces for each of the functions in `fs`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_lanczos_m</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">niters</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">)</span>
    <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">fs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ts</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fs</span><span class="p">):</span>
        <span class="n">expeig</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">eigvals</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">niters</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="n">sqeigv1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">traces</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">expeig</span> <span class="o">*</span> <span class="n">sqeigv1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">traces</span>


<span class="k">def</span> <span class="nf">_slq_red_var</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the trace of matrix exponential with reduced variance</span>

<span class="sd">    Args:</span>
<span class="sd">        A: Square matrix in trace(exp(-t*A)), where t is temperature.</span>
<span class="sd">        m: Number of Lanczos steps.</span>
<span class="sd">        niters: Number of quadratures (also, the number of random vectors in the hutchinson trace estimator).</span>
<span class="sd">        ts: Array with temperatures.</span>

<span class="sd">    Returns:</span>
<span class="sd">        traces: Estimate of trace for each temperature value in `ts`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">]</span>

    <span class="n">traces</span> <span class="o">=</span> <span class="n">_slq_ts_fs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">niters</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">,</span> <span class="n">fs</span><span class="p">)</span>
    <span class="n">subee</span> <span class="o">=</span> <span class="n">traces</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">traces</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="o">-</span> <span class="n">ts</span> <span class="o">*</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">subee</span> <span class="o">+</span> <span class="n">sub</span>


<span class="k">def</span> <span class="nf">_build_graph</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return Laplacian from data or load preconstructed from path</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Samples.</span>
<span class="sd">        k: Number of neighbours for graph construction.</span>
<span class="sd">        normalized: if True, use nnormalized Laplacian.</span>

<span class="sd">    Returns:</span>
<span class="sd">        L: Laplacian of the graph constructed with data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">_construct_graph_sparse</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">A</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">_laplacian_sparse</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">normalized</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">L</span>


<span class="k">def</span> <span class="nf">_normalize_msid</span><span class="p">(</span><span class="n">msid</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">normalization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">normed_msid</span> <span class="o">=</span> <span class="n">msid</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">normalization</span> <span class="o">==</span> <span class="s1">&#39;empty&#39;</span><span class="p">:</span>
        <span class="n">normed_msid</span> <span class="o">/=</span> <span class="n">n</span>
    <span class="k">elif</span> <span class="n">normalization</span> <span class="o">==</span> <span class="s1">&#39;complete&#39;</span><span class="p">:</span>
        <span class="n">normed_msid</span> <span class="o">/=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">ts</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">normalization</span> <span class="o">==</span> <span class="s1">&#39;er&#39;</span><span class="p">:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">er_spectrum</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">*</span> <span class="n">xs</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="n">er_msid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">er_spectrum</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">normed_msid</span> <span class="o">=</span> <span class="n">normed_msid</span> <span class="o">/</span> <span class="p">(</span><span class="n">er_msid</span> <span class="o">+</span> <span class="n">EPSILON</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">normalization</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span> <span class="ow">or</span> <span class="n">normalization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown normalization parameter!&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">normed_msid</span>


<span class="k">def</span> <span class="nf">_msid_descriptor</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                     <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">normalized_laplacian</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">normalize</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;empty&#39;</span><span class="p">)</span> \
        <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the msid descriptor for a single set of samples</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Samples from data distribution. Shape (N_samples, data_dim)</span>
<span class="sd">        ts: Temperature values.</span>
<span class="sd">        k: Number of neighbours for graph construction.</span>
<span class="sd">        m: Lanczos steps in SLQ.</span>
<span class="sd">        niters: Number of starting random vectors for SLQ.</span>
<span class="sd">        rademacher: True to use Rademacher distribution,</span>
<span class="sd">            False - standard normal for random vectors in Hutchinson.</span>
<span class="sd">        normalized_laplacian: if True, use normalized Laplacian</span>
<span class="sd">        normalize: &#39;empty&#39; for average heat kernel (corresponds to the empty graph normalization of NetLSD),</span>
<span class="sd">                &#39;complete&#39; for the complete, &#39;er&#39; for erdos-renyi normalization, &#39;none&#39; for no normalization</span>
<span class="sd">    Returns:</span>
<span class="sd">        normed_msidx: normalized msid descriptor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">scipy</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Scipy is required for computation of the Geometry Score but not installed. &quot;</span>
                          <span class="s2">&quot;Please install scipy using the following command: pip install --user scipy&quot;</span><span class="p">)</span>

    <span class="n">recommended_scipy_version</span> <span class="o">=</span> <span class="n">_parse_version</span><span class="p">(</span><span class="s2">&quot;1.3.3&quot;</span><span class="p">)</span>
    <span class="n">scipy_version</span> <span class="o">=</span> <span class="n">_parse_version</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">scipy_version</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">scipy_version</span> <span class="o">&lt;</span> <span class="n">recommended_scipy_version</span><span class="p">:</span>
        <span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Scipy of version </span><span class="si">{</span><span class="n">scipy</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s1"> is used while version &gt;= </span><span class="si">{</span><span class="n">recommended_scipy_version</span><span class="si">}</span><span class="s1"> is &#39;</span>
             <span class="sa">f</span><span class="s1">&#39;recommended. Consider updating scipy to avoid potential long compute time with older versions.&#39;</span><span class="p">)</span>

    <span class="n">Lx</span> <span class="o">=</span> <span class="n">_build_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">normalized_laplacian</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="n">Lx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">msidx</span> <span class="o">=</span> <span class="n">_slq_red_var</span><span class="p">(</span><span class="n">Lx</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">niters</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">rademacher</span><span class="p">)</span>

    <span class="n">normed_msidx</span> <span class="o">=</span> <span class="n">_normalize_msid</span><span class="p">(</span><span class="n">msidx</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ts</span><span class="p">)</span> <span class="o">*</span> <span class="n">NORMALIZATION</span>

    <span class="k">return</span> <span class="n">normed_msidx</span>


<div class="viewcode-block" id="MSID">
<a class="viewcode-back" href="../../olimp/evaluation/loss.html#olimp.evaluation.loss.piq.MSID">[docs]</a>
<span class="k">class</span> <span class="nc">MSID</span><span class="p">(</span><span class="n">BaseFeatureMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a criterion that measures MSID score for two batches of images</span>
<span class="sd">    It&#39;s computed for a whole set of data and uses features from encoder instead of images itself</span>
<span class="sd">    to decrease computation cost. MSID can compare two data distributions with different</span>
<span class="sd">    number of samples or different dimensionalities.</span>

<span class="sd">    Args:</span>
<span class="sd">        ts: Temperature values. If ``None``, the default value ``torch.logspace(-1, 1, 256)`` is used.</span>
<span class="sd">        k: Number of neighbours for graph construction.</span>
<span class="sd">        m: Lanczos steps in SLQ.</span>
<span class="sd">        niters: Number of starting random vectors for SLQ.</span>
<span class="sd">        rademacher: True to use Rademacher distribution,</span>
<span class="sd">            False - standard normal for random vectors in Hutchinson.</span>
<span class="sd">        normalized_laplacian: if True, use normalized Laplacian.</span>
<span class="sd">        normalize: ``&#39;empty&#39;`` for average heat kernel (corresponds to the empty graph normalization of NetLSD),</span>
<span class="sd">            ``&#39;complete&#39;`` for the complete, ``&#39;er&#39;`` for Erdos-Renyi normalization, ``&#39;none&#39;`` for no normalization</span>
<span class="sd">        msid_mode: ``&#39;l2&#39;`` to compute the L2 norm of the distance between `msid1` and `msid2`;</span>
<span class="sd">            ``&#39;max&#39;`` to find the maximum absolute difference between two descriptors over temperature</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; msid_metric = MSID()</span>
<span class="sd">        &gt;&gt;&gt; x_feats = torch.rand(10000, 1024)</span>
<span class="sd">        &gt;&gt;&gt; y_feats = torch.rand(10000, 1024)</span>
<span class="sd">        &gt;&gt;&gt; msid: torch.Tensor = msid_metric(x_feats, y_feats)</span>

<span class="sd">    References:</span>
<span class="sd">        Tsitsulin, A., Munkhoeva, M., Mottin, D., Karras, P., Bronstein, A., Oseledets, I., &amp; Mller, E. (2019).</span>
<span class="sd">        The shape of data: Intrinsic distance for data distributions.</span>
<span class="sd">        https://arxiv.org/abs/1905.11141</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">niters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
                 <span class="n">rademacher</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">normalized_laplacian</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">normalize</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;empty&#39;</span><span class="p">,</span>
                 <span class="n">msid_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MSID</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">ts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># MSID works only with Numpy tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rademacher</span> <span class="o">=</span> <span class="n">rademacher</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">msid_mode</span> <span class="o">=</span> <span class="n">msid_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_laplacian</span> <span class="o">=</span> <span class="n">normalized_laplacian</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

<div class="viewcode-block" id="MSID.compute_metric">
<a class="viewcode-back" href="../../olimp/evaluation/loss.html#olimp.evaluation.loss.piq.MSID.compute_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute MSID score between two sets of samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x_features: Samples from data distribution. Shape :math:`(N_x, D_x)`</span>
<span class="sd">            y_features: Samples from data distribution. Shape :math:`(N_y, D_y)`</span>

<span class="sd">        Returns:</span>
<span class="sd">            Scalar value of the distance between distributions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_validate_input</span><span class="p">([</span><span class="n">x_features</span><span class="p">,</span> <span class="n">y_features</span><span class="p">],</span> <span class="n">dim_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">size_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">normed_msid_x</span> <span class="o">=</span> <span class="n">_msid_descriptor</span><span class="p">(</span>
            <span class="n">x_features</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">ts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ts</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
            <span class="n">m</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
            <span class="n">niters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">,</span>
            <span class="n">rademacher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rademacher</span><span class="p">,</span>
            <span class="n">normalized_laplacian</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_laplacian</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalize</span>
        <span class="p">)</span>
        <span class="n">normed_msid_y</span> <span class="o">=</span> <span class="n">_msid_descriptor</span><span class="p">(</span>
            <span class="n">y_features</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">ts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ts</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
            <span class="n">m</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
            <span class="n">niters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">niters</span><span class="p">,</span>
            <span class="n">rademacher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rademacher</span><span class="p">,</span>
            <span class="n">normalized_laplacian</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_laplacian</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalize</span>
        <span class="p">)</span>

        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ts</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">ts</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">msid_mode</span> <span class="o">==</span> <span class="s1">&#39;l2&#39;</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">normed_msid_x</span> <span class="o">-</span> <span class="n">normed_msid_y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">msid_mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">normed_msid_x</span> <span class="o">-</span> <span class="n">normed_msid_y</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Mode must be in {`l2`, `max`}&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x_features</span><span class="o">.</span><span class="n">device</span><span class="p">)</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">PyOlimp</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/processing.html">olimp.processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html">olimp.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.chromaticity_difference">olimp.evaluation.loss.chromaticity_difference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.color_blindness_loss">olimp.evaluation.loss.color_blindness_loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.corr">olimp.evaluation.loss.corr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.flip">olimp.evaluation.loss.flip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.lcn">olimp.evaluation.loss.lcn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.mse">olimp.evaluation.loss.mse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.nrmse">olimp.evaluation.loss.nrmse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.piq">olimp.evaluation.loss.piq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.psnr">olimp.evaluation.loss.psnr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.rms">olimp.evaluation.loss.rms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.s_oklab">olimp.evaluation.loss.s_oklab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.ssim">olimp.evaluation.loss.ssim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.stress">olimp.evaluation.loss.stress</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/evaluation/loss.html#module-olimp.evaluation.loss.vsi">olimp.evaluation.loss.vsi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/simulate.html">olimp.simulate.color_blindness_distortion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/simulate.html#module-olimp.simulate.refraction_distortion">olimp.simulate.refraction_distortion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/basic.html">olimp.precompensation.basic.huang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/analytics.html">olimp.precompensation.analytics.feng_xu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/optimization.html">olimp.precompensation.optimization.bregman_jumbo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/optimization.html#module-olimp.precompensation.optimization.global_tone_mapping">olimp.precompensation.optimization.global_tone_mapping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/optimization.html#module-olimp.precompensation.optimization.montalto">olimp.precompensation.optimization.montalto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/optimization.html#module-olimp.precompensation.optimization.tennenholtz_zachevsky">olimp.precompensation.optimization.tennenholtz_zachevsky</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/vae.html">olimp.precompensation.nn.models.vae</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/unetvae.html">olimp.precompensation.nn.models.unetvae</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/cvae.html">olimp.precompensation.nn.models.cvae</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/cvd_swin.html">olimp.precompensation.nn.models.cvd_swin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/dwdn.html">olimp.precompensation.nn.models.dwdn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/vdsr.html">olimp.precompensation.nn.models.vdsr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/unet_efficient_b0.html">olimp.precompensation.nn.models.unet_efficient_b0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../olimp/precompensation/nn/models/usrnet.html">olimp.precompensation.nn.models.usrnet</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, PyOlimp authors.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>