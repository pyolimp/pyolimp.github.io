

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Loss &mdash; PyOlimp 0.1.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=64240a9a" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=92734c54"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Processing" href="../processing.html" />
    <link rel="prev" title="Dataset" href="../dataset.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            PyOlimp
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Dataset</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Loss</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.chromaticity_difference">chromaticity_difference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.chromaticity_difference.CDBase"><code class="docutils literal notranslate"><span class="pre">CDBase</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.chromaticity_difference.Lab"><code class="docutils literal notranslate"><span class="pre">Lab</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.chromaticity_difference.ProLab"><code class="docutils literal notranslate"><span class="pre">ProLab</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.color_blindness_loss">color_blindness_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.corr">corr</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.corr.Correlation"><code class="docutils literal notranslate"><span class="pre">Correlation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.corr.Correlation.forward"><code class="docutils literal notranslate"><span class="pre">Correlation.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.flip">flip</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.HDRFLIPLoss"><code class="docutils literal notranslate"><span class="pre">HDRFLIPLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.flip.HDRFLIPLoss.forward"><code class="docutils literal notranslate"><span class="pre">HDRFLIPLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.LDRFLIPLoss"><code class="docutils literal notranslate"><span class="pre">LDRFLIPLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.flip.LDRFLIPLoss.forward"><code class="docutils literal notranslate"><span class="pre">LDRFLIPLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.color_space_transform"><code class="docutils literal notranslate"><span class="pre">color_space_transform()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.compute_ldrflip"><code class="docutils literal notranslate"><span class="pre">compute_ldrflip()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.compute_start_stop_exposures"><code class="docutils literal notranslate"><span class="pre">compute_start_stop_exposures()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.feature_detection"><code class="docutils literal notranslate"><span class="pre">feature_detection()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.generate_spatial_filter"><code class="docutils literal notranslate"><span class="pre">generate_spatial_filter()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.hunt_adjustment"><code class="docutils literal notranslate"><span class="pre">hunt_adjustment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.hyab"><code class="docutils literal notranslate"><span class="pre">hyab()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.redistribute_errors"><code class="docutils literal notranslate"><span class="pre">redistribute_errors()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.spatial_filter"><code class="docutils literal notranslate"><span class="pre">spatial_filter()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.flip.tone_map"><code class="docutils literal notranslate"><span class="pre">tone_map()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.lcn">lcn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.lcn.LCN"><code class="docutils literal notranslate"><span class="pre">LCN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.lcn.LCN.forward"><code class="docutils literal notranslate"><span class="pre">LCN.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.lcn.LCN.local_contrast_normalization"><code class="docutils literal notranslate"><span class="pre">LCN.local_contrast_normalization()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.mse">mse</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.mse.MSE"><code class="docutils literal notranslate"><span class="pre">MSE</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.mse.MSE.forward"><code class="docutils literal notranslate"><span class="pre">MSE.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.nrmse">nrmse</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.nrmse.NormalizedRootMSE"><code class="docutils literal notranslate"><span class="pre">NormalizedRootMSE</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.nrmse.NormalizedRootMSE.forward"><code class="docutils literal notranslate"><span class="pre">NormalizedRootMSE.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.piq">piq</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.BRISQUELoss"><code class="docutils literal notranslate"><span class="pre">BRISQUELoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.BRISQUELoss.forward"><code class="docutils literal notranslate"><span class="pre">BRISQUELoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.CLIPIQA"><code class="docutils literal notranslate"><span class="pre">CLIPIQA</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.CLIPIQA.forward"><code class="docutils literal notranslate"><span class="pre">CLIPIQA.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss"><code class="docutils literal notranslate"><span class="pre">ContentLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss.compute_distance"><code class="docutils literal notranslate"><span class="pre">ContentLoss.compute_distance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss.forward"><code class="docutils literal notranslate"><span class="pre">ContentLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss.get_features"><code class="docutils literal notranslate"><span class="pre">ContentLoss.get_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss.normalize"><code class="docutils literal notranslate"><span class="pre">ContentLoss.normalize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.ContentLoss.replace_pooling"><code class="docutils literal notranslate"><span class="pre">ContentLoss.replace_pooling()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.DISTS"><code class="docutils literal notranslate"><span class="pre">DISTS</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.DISTS.compute_distance"><code class="docutils literal notranslate"><span class="pre">DISTS.compute_distance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.DISTS.forward"><code class="docutils literal notranslate"><span class="pre">DISTS.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.DISTS.get_features"><code class="docutils literal notranslate"><span class="pre">DISTS.get_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.DISTS.replace_pooling"><code class="docutils literal notranslate"><span class="pre">DISTS.replace_pooling()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.DSSLoss"><code class="docutils literal notranslate"><span class="pre">DSSLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.DSSLoss.forward"><code class="docutils literal notranslate"><span class="pre">DSSLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.FID"><code class="docutils literal notranslate"><span class="pre">FID</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.FID.compute_metric"><code class="docutils literal notranslate"><span class="pre">FID.compute_metric()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.FSIMLoss"><code class="docutils literal notranslate"><span class="pre">FSIMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.FSIMLoss.forward"><code class="docutils literal notranslate"><span class="pre">FSIMLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.GMSDLoss"><code class="docutils literal notranslate"><span class="pre">GMSDLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.GMSDLoss.forward"><code class="docutils literal notranslate"><span class="pre">GMSDLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.HaarPSILoss"><code class="docutils literal notranslate"><span class="pre">HaarPSILoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.HaarPSILoss.forward"><code class="docutils literal notranslate"><span class="pre">HaarPSILoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.InformationWeightedSSIMLoss"><code class="docutils literal notranslate"><span class="pre">InformationWeightedSSIMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.InformationWeightedSSIMLoss.forward"><code class="docutils literal notranslate"><span class="pre">InformationWeightedSSIMLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.KID"><code class="docutils literal notranslate"><span class="pre">KID</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.KID.compute_metric"><code class="docutils literal notranslate"><span class="pre">KID.compute_metric()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.MDSILoss"><code class="docutils literal notranslate"><span class="pre">MDSILoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.MDSILoss.forward"><code class="docutils literal notranslate"><span class="pre">MDSILoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.MSID"><code class="docutils literal notranslate"><span class="pre">MSID</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.MSID.compute_metric"><code class="docutils literal notranslate"><span class="pre">MSID.compute_metric()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.MultiScaleGMSDLoss"><code class="docutils literal notranslate"><span class="pre">MultiScaleGMSDLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.MultiScaleGMSDLoss.forward"><code class="docutils literal notranslate"><span class="pre">MultiScaleGMSDLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.MultiScaleSSIMLoss"><code class="docutils literal notranslate"><span class="pre">MultiScaleSSIMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.MultiScaleSSIMLoss.forward"><code class="docutils literal notranslate"><span class="pre">MultiScaleSSIMLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.PR"><code class="docutils literal notranslate"><span class="pre">PR</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.PR.compute_metric"><code class="docutils literal notranslate"><span class="pre">PR.compute_metric()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.PieAPP"><code class="docutils literal notranslate"><span class="pre">PieAPP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.PieAPP.forward"><code class="docutils literal notranslate"><span class="pre">PieAPP.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.PieAPP.get_features"><code class="docutils literal notranslate"><span class="pre">PieAPP.get_features()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.SRSIMLoss"><code class="docutils literal notranslate"><span class="pre">SRSIMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.SRSIMLoss.forward"><code class="docutils literal notranslate"><span class="pre">SRSIMLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.SSIMLoss"><code class="docutils literal notranslate"><span class="pre">SSIMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.SSIMLoss.forward"><code class="docutils literal notranslate"><span class="pre">SSIMLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.StyleLoss"><code class="docutils literal notranslate"><span class="pre">StyleLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.StyleLoss.compute_distance"><code class="docutils literal notranslate"><span class="pre">StyleLoss.compute_distance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.StyleLoss.gram_matrix"><code class="docutils literal notranslate"><span class="pre">StyleLoss.gram_matrix()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.TVLoss"><code class="docutils literal notranslate"><span class="pre">TVLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.TVLoss.forward"><code class="docutils literal notranslate"><span class="pre">TVLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.VIFLoss"><code class="docutils literal notranslate"><span class="pre">VIFLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.VIFLoss.forward"><code class="docutils literal notranslate"><span class="pre">VIFLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.VSILoss"><code class="docutils literal notranslate"><span class="pre">VSILoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.piq.VSILoss.forward"><code class="docutils literal notranslate"><span class="pre">VSILoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.total_variation"><code class="docutils literal notranslate"><span class="pre">total_variation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.piq.vif_p"><code class="docutils literal notranslate"><span class="pre">vif_p()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.psnr">psnr</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.psnr.PSNR"><code class="docutils literal notranslate"><span class="pre">PSNR</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.psnr.PSNR.forward"><code class="docutils literal notranslate"><span class="pre">PSNR.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.rms">rms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.rms.RMS"><code class="docutils literal notranslate"><span class="pre">RMS</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.s_oklab">s_oklab</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.s_oklab.SOkLab"><code class="docutils literal notranslate"><span class="pre">SOkLab</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.ssim">ssim</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.ssim.ContrastLoss"><code class="docutils literal notranslate"><span class="pre">ContrastLoss</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.ssim.SSIMLoss"><code class="docutils literal notranslate"><span class="pre">SSIMLoss</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.stress">stress</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#olimp.evaluation.loss.stress.STRESS"><code class="docutils literal notranslate"><span class="pre">STRESS</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#olimp.evaluation.loss.stress.STRESS.forward"><code class="docutils literal notranslate"><span class="pre">STRESS.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-olimp.evaluation.loss.lpips">lpips</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../processing.html">Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../simulate.html">Simulate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train_configuration.html">Train Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../precompensation/index.html">Precompensation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyOlimp</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Loss</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/olimp/evaluation/loss.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="loss">
<h1>Loss<a class="headerlink" href="#loss" title="Link to this heading"></a></h1>
<section id="module-olimp.evaluation.loss.chromaticity_difference">
<span id="chromaticity-difference"></span><h2>chromaticity_difference<a class="headerlink" href="#module-olimp.evaluation.loss.chromaticity_difference" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.chromaticity_difference.CDBase">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.chromaticity_difference.</span></span><span class="sig-name descname"><span class="pre">CDBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lightness_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/chromaticity_difference.html#CDBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.chromaticity_difference.CDBase" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.chromaticity_difference.Lab">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.chromaticity_difference.</span></span><span class="sig-name descname"><span class="pre">Lab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lightness_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/chromaticity_difference.html#Lab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.chromaticity_difference.Lab" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.chromaticity_difference.ProLab">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.chromaticity_difference.</span></span><span class="sig-name descname"><span class="pre">ProLab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lightness_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/chromaticity_difference.html#ProLab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.chromaticity_difference.ProLab" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-olimp.evaluation.loss.color_blindness_loss">
<span id="color-blindness-loss"></span><h2>color_blindness_loss<a class="headerlink" href="#module-olimp.evaluation.loss.color_blindness_loss" title="Link to this heading"></a></h2>
</section>
<section id="module-olimp.evaluation.loss.corr">
<span id="corr"></span><h2>corr<a class="headerlink" href="#module-olimp.evaluation.loss.corr" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.corr.Correlation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.corr.</span></span><span class="sig-name descname"><span class="pre">Correlation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">invert</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/corr.html#Correlation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.corr.Correlation" title="Link to this definition"></a></dt>
<dd><p>Computes the correlation coefficient between two tensors.</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.corr.Correlation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/corr.html#Correlation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.corr.Correlation.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the correlation coefficient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – First input tensor.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Second input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed correlation value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.flip">
<span id="flip"></span><h2>flip<a class="headerlink" href="#module-olimp.evaluation.loss.flip" title="Link to this heading"></a></h2>
<p>FLIP metric functions</p>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.HDRFLIPLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">HDRFLIPLoss</span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#HDRFLIPLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.HDRFLIPLoss" title="Link to this definition"></a></dt>
<dd><p>Class for computing HDR-FLIP</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.HDRFLIPLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels_per_degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">67.02064327658226</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tone_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'reinhard'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'hable'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'aces'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'aces'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_exposure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_exposure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#HDRFLIPLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.HDRFLIPLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the HDR-FLIP error map between two HDR images,
assuming the images are observed at a certain number of
pixels per degree of visual angle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>test</strong> – test tensor (with NxCxHxW layout with nonnegative values)</p></li>
<li><p><strong>reference</strong> – reference tensor (with NxCxHxW layout with nonnegative values)</p></li>
<li><p><strong>pixels_per_degree</strong> – float describing the number of pixels per degree of visual angle of the observer,
default corresponds to viewing the images on a 0.7 meters wide 4K monitor at 0.7 meters from the display</p></li>
<li><p><strong>tone_mapper</strong> – (optional) string describing what tone mapper HDR-FLIP should assume</p></li>
<li><p><strong>start_exposure</strong> – (optional tensor (with Nx1x1x1 layout) with start exposures corresponding to each HDR reference/test pair</p></li>
<li><p><strong>stop_exposure</strong> – (optional) tensor (with Nx1x1x1 layout) with stop exposures corresponding to each HDR reference/test pair</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>float containing the mean FLIP error (in the range [0,1]) between the HDR reference and test images in the batch</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.LDRFLIPLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">LDRFLIPLoss</span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#LDRFLIPLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.LDRFLIPLoss" title="Link to this definition"></a></dt>
<dd><p>Class for computing LDR FLIP loss</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.LDRFLIPLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels_per_degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">67.02064327658226</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#LDRFLIPLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.LDRFLIPLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the LDR-FLIP error map between two LDR images,
assuming the images are observed at a certain number of
pixels per degree of visual angle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>test</strong> – test tensor (with NxCxHxW layout with values in the range [0, 1] in the sRGB color space)</p></li>
<li><p><strong>reference</strong> – reference tensor (with NxCxHxW layout with values in the range [0, 1] in the sRGB color space)</p></li>
<li><p><strong>pixels_per_degree</strong> – float describing the number of pixels per degree of visual angle of the observer,
default corresponds to viewing the images on a 0.7 meters wide 4K monitor at 0.7 meters from the display</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>float containing the mean FLIP error (in the range [0,1]) between the LDR reference and test images in the batch</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.color_space_transform">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">color_space_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_color</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fromSpace2toSpace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'srgb2linrgb'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'linrgb2srgb'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'linrgb2xyz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'xyz2linrgb'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'xyz2ycxcz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ycxcz2xyz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'xyz2lab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lab2xyz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'srgb2xyz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'srgb2ycxcz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'linrgb2ycxcz'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'srgb2lab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'linrgb2lab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ycxcz2linrgb'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lab2srgb'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ycxcz2lab'</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#color_space_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.color_space_transform" title="Link to this definition"></a></dt>
<dd><p>Transforms inputs between different color spaces</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_color</strong> – tensor of colors to transform (with NxCxHxW layout)</p></li>
<li><p><strong>fromSpace2toSpace</strong> – string describing transform</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>transformed tensor (with NxCxHxW layout)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.compute_ldrflip">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">compute_ldrflip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels_per_degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#compute_ldrflip"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.compute_ldrflip" title="Link to this definition"></a></dt>
<dd><p>Computes the LDR-FLIP error map between two LDR images,
assuming the images are observed at a certain number of
pixels per degree of visual angle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reference</strong> – reference tensor (with NxCxHxW layout with values in the YCxCz color space)</p></li>
<li><p><strong>test</strong> – test tensor (with NxCxHxW layout with values in the YCxCz color space)</p></li>
<li><p><strong>pixels_per_degree</strong> – float describing the number of pixels per degree of visual angle of the observer,
default corresponds to viewing the images on a 0.7 meters wide 4K monitor at 0.7 meters from the display</p></li>
<li><p><strong>qc</strong> – float describing the q_c exponent in the LDR-FLIP color pipeline (see FLIP paper for details)</p></li>
<li><p><strong>qf</strong> – float describing the q_f exponent in the LDR-FLIP feature pipeline (see FLIP paper for details)</p></li>
<li><p><strong>pc</strong> – float describing the p_c exponent in the LDR-FLIP color pipeline (see FLIP paper for details)</p></li>
<li><p><strong>pt</strong> – float describing the p_t exponent in the LDR-FLIP color pipeline (see FLIP paper for details)</p></li>
<li><p><strong>eps</strong> – float containing a small value used to improve training stability</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tensor containing the per-pixel FLIP errors (with Nx1xHxW layout and values in the range [0, 1]) between LDR reference and test images</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.compute_start_stop_exposures">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">compute_start_stop_exposures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tone_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'reinhard'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'hable'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tmax</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tmin</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#compute_start_stop_exposures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.compute_start_stop_exposures" title="Link to this definition"></a></dt>
<dd><p>Computes start and stop exposure for HDR-FLIP based on given tone mapper and reference image.
Refer to the Visualizing Errors in Rendered High Dynamic Range Images
paper for details about the formulas</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reference</strong> – float tensor (with NxCxHxW layout) containing reference images (nonnegative values)</p></li>
<li><p><strong>tone_mapper</strong> – string describing which tone mapper should be assumed</p></li>
<li><p><strong>tmax</strong> – float describing the t value used to find the start exposure</p></li>
<li><p><strong>tmin</strong> – float describing the t value used to find the stop exposure</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>two float tensors (with Nx1x1x1 layout) containing start and stop exposures, respectively, to use for HDR-FLIP</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.feature_detection">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">feature_detection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels_per_degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'edge'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#feature_detection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.feature_detection" title="Link to this definition"></a></dt>
<dd><p>Detects edges and points (features) in the achromatic image</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>imgy</strong> – achromatic image tensor (with Nx1xHxW layout, containing normalized Y-values from YCxCz)</p></li>
<li><p><strong>pixels_per_degree</strong> – float describing the number of pixels per degree of visual angle of the observer</p></li>
<li><p><strong>feature_type</strong> – string indicating the type of feature to detect</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>image tensor (with Nx2xHxW layout, with values in range [0,1]) containing large values where features were detected</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.generate_spatial_filter">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">generate_spatial_filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pixels_per_degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'A'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'RG'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'BY'</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#generate_spatial_filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.generate_spatial_filter" title="Link to this definition"></a></dt>
<dd><p>Generates spatial contrast sensitivity filters with width depending on
the number of pixels per degree of visual angle of the observer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pixels_per_degree</strong> – float indicating number of pixels per degree of visual angle</p></li>
<li><p><strong>channel</strong> – string describing what filter should be generated</p></li>
</ul>
</dd>
<dt class="field-even">Yield<span class="colon">:</span></dt>
<dd class="field-even"><p>Filter kernel corresponding to the spatial contrast sensitivity function of the given channel and kernel’s radius</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.hunt_adjustment">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">hunt_adjustment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#hunt_adjustment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.hunt_adjustment" title="Link to this definition"></a></dt>
<dd><p>Applies Hunt-adjustment to an image</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> – image tensor to adjust (with NxCxHxW layout in the L*a*b* color space)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Hunt-adjusted image tensor (with NxCxHxW layout in the Hunt-adjusted L*A*B* color space)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.hyab">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">hyab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#hyab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.hyab" title="Link to this definition"></a></dt>
<dd><p>Computes the HyAB distance between reference and test images</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reference</strong> – reference image tensor (with NxCxHxW layout in the standard or Hunt-adjusted L*A*B* color space)</p></li>
<li><p><strong>test</strong> – test image tensor (with NxCxHxW layout in the standard or Hunt-adjusted L*a*b* color space)</p></li>
<li><p><strong>eps</strong> – float containing a small value used to improve training stability</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>image tensor (with Nx1xHxW layout) containing the per-pixel HyAB distances between reference and test images</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.redistribute_errors">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">redistribute_errors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power_deltaE_hyab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmax</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#redistribute_errors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.redistribute_errors" title="Link to this definition"></a></dt>
<dd><p>Redistributes exponentiated HyAB errors to the [0,1] range</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>power_deltaE_hyab</strong> – float tensor (with Nx1xHxW layout) containing the exponentiated HyAb distance</p></li>
<li><p><strong>cmax</strong> – float containing the exponentiated, maximum HyAB difference between two colors in Hunt-adjusted L*A*B* space</p></li>
<li><p><strong>pc</strong> – float containing the cmax multiplier p_c (see FLIP paper)</p></li>
<li><p><strong>pt</strong> – float containing the target value, p_t, for p_c * cmax (see FLIP paper)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>image tensor (with Nx1xHxW layout) containing redistributed per-pixel HyAB distances (in range [0,1])</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.spatial_filter">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">spatial_filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s_a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s_rg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s_by</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#spatial_filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.spatial_filter" title="Link to this definition"></a></dt>
<dd><p>Filters an image with channel specific spatial contrast sensitivity functions
and clips result to the unit cube in linear RGB</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> – image tensor to filter (with NxCxHxW layout in the YCxCz color space)</p></li>
<li><p><strong>s_a</strong> – spatial filter matrix for the achromatic channel</p></li>
<li><p><strong>s_rg</strong> – spatial filter matrix for the red-green channel</p></li>
<li><p><strong>s_by</strong> – spatial filter matrix for the blue-yellow channel</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>input image (with NxCxHxW layout) transformed to linear RGB after filtering with spatial contrast sensitivity functions</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.flip.tone_map">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.flip.</span></span><span class="sig-name descname"><span class="pre">tone_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tone_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'reinhard'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'hable'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'aces'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exposure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/flip.html#tone_map"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.flip.tone_map" title="Link to this definition"></a></dt>
<dd><p>Applies exposure compensation and tone mapping.
Refer to the Visualizing Errors in Rendered High Dynamic Range Images
paper for details about the formulas.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> – float tensor (with NxCxHxW layout) containing nonnegative values</p></li>
<li><p><strong>tone_mapper</strong> – string describing the tone mapper to apply</p></li>
<li><p><strong>exposure</strong> – float tensor (with Nx1x1x1 layout) describing the exposure compensation factor</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.lcn">
<span id="lcn"></span><h2>lcn<a class="headerlink" href="#module-olimp.evaluation.loss.lcn" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.lcn.LCN">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.lcn.</span></span><span class="sig-name descname"><span class="pre">LCN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">invert</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/lcn.html#LCN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.lcn.LCN" title="Link to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.lcn.LCN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/lcn.html#LCN.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.lcn.LCN.forward" title="Link to this definition"></a></dt>
<dd><p>Forward method to compute similarity between two images after LCN.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The first image in the format [B, C, H, W].</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – The second image in the format [B, C, H, W].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Similarity value between 0 and 1.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.lcn.LCN.local_contrast_normalization">
<span class="sig-name descname"><span class="pre">local_contrast_normalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/lcn.html#LCN.local_contrast_normalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.lcn.LCN.local_contrast_normalization" title="Link to this definition"></a></dt>
<dd><p>Performs local contrast normalization on an image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Tensor</em>) – Input image in the format [B, C, H, W].</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – A small value to avoid division by zero.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalized image.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.mse">
<span id="mse"></span><h2>mse<a class="headerlink" href="#module-olimp.evaluation.loss.mse" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.mse.MSE">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.mse.</span></span><span class="sig-name descname"><span class="pre">MSE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/mse.html#MSE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.mse.MSE" title="Link to this definition"></a></dt>
<dd><p>Mean Squared Error (MSE) metric implemented as a PyTorch module.</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.mse.MSE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/mse.html#MSE.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.mse.MSE.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the Mean Squared Error (MSE) between two tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – First input tensor.</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Second input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed MSE value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.nrmse">
<span id="nrmse"></span><h2>nrmse<a class="headerlink" href="#module-olimp.evaluation.loss.nrmse" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.nrmse.NormalizedRootMSE">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.nrmse.</span></span><span class="sig-name descname"><span class="pre">NormalizedRootMSE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'euclidean'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'min-max'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mean'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">invert</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/nrmse.html#NormalizedRootMSE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.nrmse.NormalizedRootMSE" title="Link to this definition"></a></dt>
<dd><p>Normalized Root Mean Squared Error (NRMSE) loss in PyTorch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalization</strong> (<em>str</em>) – The normalization type. Options are ‘euclidean’, ‘min-max’, or ‘mean’.</p></li>
<li><p><strong>invert</strong> (<em>bool</em>) – If True, returns <cite>1 - NRMSE</cite> for compatibility with certain metrics.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.nrmse.NormalizedRootMSE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/nrmse.html#NormalizedRootMSE.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.nrmse.NormalizedRootMSE.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the Normalized Root Mean Squared Error (NRMSE) between two tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Ground truth tensor.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Predicted tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed NRMSE value. If invert is True, returns <cite>1 - NRMSE</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.piq">
<span id="piq"></span><h2>piq<a class="headerlink" href="#module-olimp.evaluation.loss.piq" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.BRISQUELoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">BRISQUELoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.1666666666666667</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/brisque.html#BRISQUELoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.BRISQUELoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the BRISQUE score for input <span class="math notranslate nohighlight">\(x\)</span>.
<span class="math notranslate nohighlight">\(x\)</span> is 4D tensor (N, C, H, W).
The sum operation still operates over all the elements, and divides by <span class="math notranslate nohighlight">\(n\)</span>.
The division by <span class="math notranslate nohighlight">\(n\)</span> can be avoided by setting <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – By default, the mean and covariance of a pixel is obtained
by convolution with given filter_size. Must be an odd value.</p></li>
<li><p><strong>kernel_sigma</strong> – Standard deviation for Gaussian kernel.</p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">BRISQUELoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Anish Mittal et al. “No-Reference Image Quality Assessment in the Spatial Domain”,
<a class="reference external" href="https://live.ece.utexas.edu/publications/2012/TIP%20BRISQUE.pdf">https://live.ece.utexas.edu/publications/2012/TIP%20BRISQUE.pdf</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The back propagation is not available using <code class="docutils literal notranslate"><span class="pre">torch=1.5.0</span></code> due to bug in <code class="docutils literal notranslate"><span class="pre">argmin</span></code> and <code class="docutils literal notranslate"><span class="pre">argmax</span></code>
backpropagation. Update the torch and torchvision to the latest versions.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.BRISQUELoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/brisque.html#BRISQUELoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.BRISQUELoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of BRISQUE score as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – An input tensor with (N, C, H, W) shape. RGB channel order for colour images.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of BRISQUE loss to be minimized.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.CLIPIQA">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">CLIPIQA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/clip_iqa.html#CLIPIQA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.CLIPIQA" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures image quality based on a general notion of text-to-image similarity
learned by the CLIP model (Radford et al., 2021) during its large-scale pre-training on a large dataset
with paired texts and images.</p>
<p>The method is based on the idea that two antonyms (“Good photo” and “Bad photo”) can be used as anchors in the
text embedding space representing good and bad images in terms of their image quality.</p>
<p>After the anchors are defined, one can use them to determine the quality of a given image in the following way:
1. Compute the image embedding of the image of interest using the pre-trained CLIP model;
2. Compute the text embeddings of the selected anchor antonyms;
3. Compute the angle (cosine similarity) between the image embedding (1) and both text embeddings (2);
4. Compute the Softmax of cosine similarities (3) -&gt; CLIP-IQA score (Wang et al., 2022).</p>
<p>This method is proposed to eliminate the linguistic ambiguity of the naive approach
(using a single prompt, e.g., “Good photo”).</p>
<p>This method has an extension called CLIP-IQA+ proposed in the same research paper.
It uses the same approach but also fine-tunes the CLIP weights using the CoOp
fine-tuning algorithm (Zhou et al., 2022).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The initial computation of the metric is performed in <cite>float32</cite> and other dtypes (i.e. <cite>float16</cite>, <cite>float64</cite>)
are not supported. We preserve this behaviour for reproducibility perposes. Also, at the time of writing
conv2d is not supported for <cite>float16</cite> tensors on CPU.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In order to avoid implicit dtype conversion and normalization of input tensors, they are copied.
Note that it may consume extra memory, which might be noticeable on large batch sizes.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">piq</span> <span class="kn">import</span> <span class="n">CLIPIQA</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clipiqa</span> <span class="o">=</span> <span class="n">CLIPIQA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score</span> <span class="o">=</span> <span class="n">clipiqa</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Radford, Alec, et al. “Learning transferable visual models from natural language supervision.”
International conference on machine learning. PMLR, 2021.</p>
<p>Wang, Jianyi, Kelvin CK Chan, and Chen Change Loy. “Exploring CLIP for Assessing the Look
and Feel of Images.” arXiv preprint arXiv:2207.12396 (2022).</p>
<p>Zhou, Kaiyang, et al. “Learning to prompt for vision-language models.” International
Journal of Computer Vision 130.9 (2022): 2337-2348.</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.CLIPIQA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/clip_iqa.html#CLIPIQA.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.CLIPIQA.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of CLIP-IQA metric for a given image <span class="math notranslate nohighlight">\(x\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.
The metric is designed in such a way that it expects:
- A 4D PyTorch tensor;
- The tensor might have flexible data ranges depending on <cite>data_range</cite> value;
- The tensor must have channels first format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The value of CLI-IQA score in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">ContentLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_extractor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Module</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'vgg16'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">('relu3_3',)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[1.0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_pooling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_layers_weights_mismatch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss" title="Link to this definition"></a></dt>
<dd><p>Creates Content loss that can be used for image style transfer or as a measure for image to image tasks.
Uses pretrained VGG models from torchvision.
Expects input to be in range [0, 1] or normalized with ImageNet statistics into range [-1, 1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_extractor</strong> – Model to extract features or model name: <code class="docutils literal notranslate"><span class="pre">'vgg16'</span></code> | <code class="docutils literal notranslate"><span class="pre">'vgg19'</span></code>.</p></li>
<li><p><strong>layers</strong> – List of strings with layer names. Default: <code class="docutils literal notranslate"><span class="pre">'relu3_3'</span></code></p></li>
<li><p><strong>weights</strong> – List of float weight to balance different layers</p></li>
<li><p><strong>replace_pooling</strong> – Flag to replace MaxPooling layer with AveragePooling. See references for details.</p></li>
<li><p><strong>distance</strong> – Method to compute distance between features: <code class="docutils literal notranslate"><span class="pre">'mse'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mae'</span></code>.</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>mean</strong> – List of float values used for data standardization. Default: ImageNet mean.
If there is no need to normalize data, use [0., 0., 0.].</p></li>
<li><p><strong>std</strong> – List of float values used for data standardization. Default: ImageNet std.
If there is no need to normalize data, use [1., 1., 1.].</p></li>
<li><p><strong>normalize_features</strong> – If true, unit-normalize each feature in channel dimension before scaling
and computing distance. See references for details.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">ContentLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Gatys, Leon and Ecker, Alexander and Bethge, Matthias (2016).
A Neural Algorithm of Artistic Style
Association for Research in Vision and Ophthalmology (ARVO)
<a class="reference external" href="https://arxiv.org/abs/1508.06576">https://arxiv.org/abs/1508.06576</a></p>
<p>Zhang, Richard and Isola, Phillip and Efros, et al. (2018)
The Unreasonable Effectiveness of Deep Features as a Perceptual Metric
IEEE/CVF Conference on Computer Vision and Pattern Recognition
<a class="reference external" href="https://arxiv.org/abs/1801.03924">https://arxiv.org/abs/1801.03924</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss.compute_distance">
<span class="sig-name descname"><span class="pre">compute_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss.compute_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss.compute_distance" title="Link to this definition"></a></dt>
<dd><p>Take L2 or L1 distance between feature maps depending on <code class="docutils literal notranslate"><span class="pre">distance</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Features of the input tensor.</p></li>
<li><p><strong>y_features</strong> – Features of the target tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Distance between feature maps</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Content loss between feature representations of prediction <span class="math notranslate nohighlight">\(x\)</span> and
target <span class="math notranslate nohighlight">\(y\)</span> tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Content loss between feature representations</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss.get_features">
<span class="sig-name descname"><span class="pre">get_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss.get_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss.get_features" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of features extracted from intermediate layers</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss.normalize">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss.normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss.normalize" title="Link to this definition"></a></dt>
<dd><p>Normalize feature maps in channel direction to unit length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalized input</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.ContentLoss.replace_pooling">
<span class="sig-name descname"><span class="pre">replace_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#ContentLoss.replace_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.ContentLoss.replace_pooling" title="Link to this definition"></a></dt>
<dd><p>Turn All MaxPool layers into AveragePool</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>module</strong> – Module to change MaxPool int AveragePool</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Module with AveragePool instead MaxPool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DISTS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">DISTS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/perceptual.html#DISTS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DISTS" title="Link to this definition"></a></dt>
<dd><p>Deep Image Structure and Texture Similarity metric.</p>
<p>By default expects input to be in range [0, 1], which is then normalized by ImageNet statistics into range [-1, 1].
If no normalisation is required, change <cite>mean</cite> and <cite>std</cite> values accordingly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>mean</strong> – List of float values used for data standardization. Default: ImageNet mean.
If there is no need to normalize data, use [0., 0., 0.].</p></li>
<li><p><strong>std</strong> – List of float values used for data standardization. Default: ImageNet std.
If there is no need to normalize data, use [1., 1., 1.].</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">DISTS</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Keyan Ding, Kede Ma, Shiqi Wang, Eero P. Simoncelli (2020).
Image Quality Assessment: Unifying Structure and Texture Similarity.
<a class="reference external" href="https://arxiv.org/abs/2004.07728">https://arxiv.org/abs/2004.07728</a>
<a class="reference external" href="https://github.com/dingkeyan93/DISTS">https://github.com/dingkeyan93/DISTS</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DISTS.compute_distance">
<span class="sig-name descname"><span class="pre">compute_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#DISTS.compute_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DISTS.compute_distance" title="Link to this definition"></a></dt>
<dd><p>Compute structure similarity between feature maps</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Features of the input tensor.</p></li>
<li><p><strong>y_features</strong> – Features of the target tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Structural similarity distance between feature maps</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DISTS.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#DISTS.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DISTS.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Deep Image Structure and Texture Similarity loss, i.e. <code class="docutils literal notranslate"><span class="pre">1-DISTS</span></code> in range [0, 1].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DISTS.get_features">
<span class="sig-name descname"><span class="pre">get_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#DISTS.get_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DISTS.get_features" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input tensor</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of features extracted from input tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DISTS.replace_pooling">
<span class="sig-name descname"><span class="pre">replace_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#DISTS.replace_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DISTS.replace_pooling" title="Link to this definition"></a></dt>
<dd><p>Turn All MaxPool layers into L2Pool</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>module</strong> – Module to change MaxPool into L2Pool</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Module with L2Pool instead of MaxPool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DSSLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">DSSLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dct_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.55</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_similarity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/dss.html#DSSLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DSSLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the DSS for input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>In order to be considered as a loss, value <cite>1 - clip(DSS, min=0, max=1)</cite> is returned. If you need DSS value,
use function <cite>dss</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>dct_size</strong> – Size of blocks in 2D Discrete Cosine Transform. DCT sizes must be in (0, input size].</p></li>
<li><p><strong>sigma_weight</strong> – STD of gaussian that determines the proportion of weight given to low freq and high freq.
Default: 1.55</p></li>
<li><p><strong>kernel_size</strong> – Size of gaussian kernel for computing subband similarity. Kernels size must be in (0, input size].
Default: 3</p></li>
<li><p><strong>sigma_similarity</strong> – STD of gaussian kernel for computing subband similarity. Default: 1.5</p></li>
<li><p><strong>percentile</strong> – % in (0,1] of worst similarity scores which should be kept. Default: 0.05</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: Required to be 4D (N, C, H, W). RGB channel order for colour images.</p></li>
<li><p>Target: Required to be 4D (N, C, H, W). RGB channel order for colour images.</p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">DSSLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://sse.tongji.edu.cn/linzhang/ICIP12/ICIP-SR-SIM.pdf">https://sse.tongji.edu.cn/linzhang/ICIP12/ICIP-SR-SIM.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.DSSLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/dss.html#DSSLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.DSSLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of DSS as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> – Tensor of prediction of the network.</p></li>
<li><p><strong>target</strong> – Reference tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of DSS loss to be minimized. 0 &lt;= DSS &lt;= 1.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.FID">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">FID</span></span><a class="reference internal" href="../../_modules/piq/fid.html#FID"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.FID" title="Link to this definition"></a></dt>
<dd><p>Interface of Frechet Inception Distance.
It’s computed for a whole set of data and uses features from encoder instead of images itself to decrease
computation cost. FID can compare two data distributions with different number of samples.
But dimensionalities should match, otherwise it won’t be possible to correctly compute statistics.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fid_metric</span> <span class="o">=</span> <span class="n">FID</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">fid_metric</span><span class="p">(</span><span class="n">x_feats</span><span class="p">,</span> <span class="n">y_feats</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Heusel M. et al. (2017).
Gans trained by a two time-scale update rule converge to a local nash equilibrium.
Advances in neural information processing systems,
<a class="reference external" href="https://arxiv.org/abs/1706.08500">https://arxiv.org/abs/1706.08500</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.FID.compute_metric">
<span class="sig-name descname"><span class="pre">compute_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/fid.html#FID.compute_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.FID.compute_metric" title="Link to this definition"></a></dt>
<dd><p>Fits multivariate Gaussians: <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu_x, \sigma_x)\)</span> and
<span class="math notranslate nohighlight">\(Y \sim \mathcal{N}(\mu_y, \sigma_y)\)</span> to image stacks.
Then computes FID as <span class="math notranslate nohighlight">\(d^2 = ||\mu_x - \mu_y||^2 + Tr(\sigma_x + \sigma_y - 2\sqrt{\sigma_x \sigma_y})\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_x, D)\)</span></p></li>
<li><p><strong>y_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_y, D)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Frechet Distance.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.FSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">FSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chromatic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orientations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mult</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_f</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.55</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta_theta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/fsim.html#FSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.FSIMLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the FSIM or FSIMc for input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>In order to be considered as a loss, value <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">clip(FSIM,</span> <span class="pre">min=0,</span> <span class="pre">max=1)</span></code> is returned. If you need FSIM value,
use function <cite>fsim</cite> instead.
Supports greyscale and colour images with RGB channel order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>chromatic</strong> – Flag to compute FSIMc, which also takes into account chromatic components</p></li>
<li><p><strong>scales</strong> – Number of wavelets used for computation of phase congruensy maps</p></li>
<li><p><strong>orientations</strong> – Number of filter orientations used for computation of phase congruensy maps</p></li>
<li><p><strong>min_length</strong> – Wavelength of smallest scale filter</p></li>
<li><p><strong>mult</strong> – Scaling factor between successive filters</p></li>
<li><p><strong>sigma_f</strong> – Ratio of the standard deviation of the Gaussian describing the log Gabor filter’s
transfer function in the frequency domain to the filter center frequency.</p></li>
<li><p><strong>delta_theta</strong> – Ratio of angular interval between filter orientations and the standard deviation
of the angular Gaussian function used to construct filters in the frequency plane.</p></li>
<li><p><strong>k</strong> – No of standard deviations of the noise energy beyond the mean at which we set the noise
threshold  point, below which phase congruency values get penalized.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">FSIMLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>L. Zhang, L. Zhang, X. Mou and D. Zhang, “FSIM: A Feature Similarity Index for Image Quality Assessment,”
IEEE Transactions on Image Processing, vol. 20, no. 8, pp. 2378-2386, Aug. 2011, doi: 10.1109/TIP.2011.2109730.
<a class="reference external" href="https://ieeexplore.ieee.org/document/5705575">https://ieeexplore.ieee.org/document/5705575</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.FSIMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/fsim.html#FSIMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.FSIMLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of FSIM as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of FSIM loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.GMSDLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">GMSDLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.00261437908496732</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/gmsd.html#GMSDLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.GMSDLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures Gradient Magnitude Similarity Deviation
between each element in the input and target.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>t</strong> – Constant from the reference paper numerical stability of similarity map</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">GMSDLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wufeng Xue et al. Gradient Magnitude Similarity Deviation (2013)
<a class="reference external" href="https://arxiv.org/pdf/1308.3052.pdf">https://arxiv.org/pdf/1308.3052.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.GMSDLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/gmsd.html#GMSDLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.GMSDLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Gradient Magnitude Similarity Deviation (GMSD) as a loss function.
Supports greyscale and colour images with RGB channel order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of GMSD loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.HaarPSILoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">HaarPSILoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4.2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/haarpsi.html#HaarPSILoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.HaarPSILoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures  Haar Wavelet-Based Perceptual Similarity loss between
each element in the input and target.</p>
<p>The sum operation still operates over all the elements, and divides by <span class="math notranslate nohighlight">\(n\)</span>.
The division by <span class="math notranslate nohighlight">\(n\)</span> can be avoided if one sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>scales</strong> – Number of Haar wavelets used for image decomposition.</p></li>
<li><p><strong>subsample</strong> – Flag to apply average pooling before HaarPSI computation. See references for details.</p></li>
<li><p><strong>c</strong> – Constant from the paper. See references for details</p></li>
<li><p><strong>alpha</strong> – Exponent used for similarity maps weightning. See references for details</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">HaarPSILoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>R. Reisenhofer, S. Bosse, G. Kutyniok &amp; T. Wiegand (2017)
‘A Haar Wavelet-Based Perceptual Similarity Index for Image Quality Assessment’
<a class="reference external" href="http://www.math.uni-bremen.de/cda/HaarPSI/publications/HaarPSI_preprint_v4.pdf">http://www.math.uni-bremen.de/cda/HaarPSI/publications/HaarPSI_preprint_v4.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.HaarPSILoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/haarpsi.html#HaarPSILoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.HaarPSILoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of HaarPSI as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of HaarPSI loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.InformationWeightedSSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">InformationWeightedSSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">11</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_nsq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/iw_ssim.html#InformationWeightedSSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.InformationWeightedSSIMLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the Interface of Information Content Weighted Structural Similarity (IW-SSIM)
index error betweeneach element in the input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Inputs supposed to be in range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">data_range]</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code> (default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}InformationWeightedSSIMLoss(x, y) =
\begin{cases}
    \operatorname{mean}(1 - IWSSIM), &amp;  \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(1 - IWSSIM),  &amp;  \text{if reduction} = \text{'sum'.}
\end{cases}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>kernel_size</strong> – The side-length of the sliding window used in comparison. Must be an odd value.</p></li>
<li><p><strong>kernel_sigma</strong> – Sigma of normal distribution for sliding window used in comparison.</p></li>
<li><p><strong>k1</strong> – Algorithm parameter, K1 (small constant).</p></li>
<li><p><strong>k2</strong> – Algorithm parameter, K2 (small constant).
Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.</p></li>
<li><p><strong>parent</strong> – Flag to control dependency on previous layer of pyramid.</p></li>
<li><p><strong>blk_size</strong> – The side-length of the sliding window used in comparison for information content.</p></li>
<li><p><strong>sigma_nsq</strong> – Sigma of normal distribution for sliding window used in comparison for information content.</p></li>
<li><p><strong>scale_weights</strong> – Weights for scaling.</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">InformationWeightedSSIMLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wang, Zhou, and Qiang Li..
Information content weighting for perceptual image quality assessment.
IEEE Transactions on image processing 20.5 (2011): 1185-1198.
<a class="reference external" href="https://ece.uwaterloo.ca/~z70wang/publications/IWSSIM.pdf">https://ece.uwaterloo.ca/~z70wang/publications/IWSSIM.pdf</a> DOI:<cite>10.1109/TIP.2010.2092435</cite></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.InformationWeightedSSIMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/iw_ssim.html#InformationWeightedSSIMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.InformationWeightedSSIMLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Information Content Weighted Structural Similarity (IW-SSIM) index as a loss function.
For colour images channel order is RGB.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of IW-SSIM loss to be minimized, i.e. <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">information_weighted_ssim</span></code> in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.KID">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">KID</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coef0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_at_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_subsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/kid.html#KID"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.KID" title="Link to this definition"></a></dt>
<dd><p>Interface of Kernel Inception Distance.
It’s computed for a whole set of data and uses features from encoder instead of images itself to decrease
computation cost. KID can compare two data distributions with different number of samples.
But dimensionalities should match, otherwise it won’t be possible to correctly compute statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degree</strong> – Degree of a polynomial functions used in kernels. Default: 3</p></li>
<li><p><strong>gamma</strong> – Kernel parameter. See paper for details</p></li>
<li><p><strong>coef0</strong> – Kernel parameter. See paper for details</p></li>
<li><p><strong>var_at_m</strong> – Kernel variance. Default is <cite>None</cite></p></li>
<li><p><strong>average</strong> – If <cite>True</cite> recomputes metric <cite>n_subsets</cite> times using <cite>subset_size</cite> elements.</p></li>
<li><p><strong>n_subsets</strong> – Number of repeats. Ignored if <cite>average</cite> is False</p></li>
<li><p><strong>subset_size</strong> – Size of each subset for repeat. Ignored if <cite>average</cite> is False</p></li>
<li><p><strong>ret_var</strong> – Whether to return variance after the distance is computed.
This function will return <code class="docutils literal notranslate"><span class="pre">Tuple[torch.Tensor,</span> <span class="pre">torch.Tensor]</span></code> in this case. Default: False</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">kid_metric</span> <span class="o">=</span> <span class="n">KID</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">kid_metric</span><span class="p">(</span><span class="n">x_feats</span><span class="p">,</span> <span class="n">y_feats</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Demystifying MMD GANs <a class="reference external" href="https://arxiv.org/abs/1801.01401">https://arxiv.org/abs/1801.01401</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.KID.compute_metric">
<span class="sig-name descname"><span class="pre">compute_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/kid.html#KID.compute_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.KID.compute_metric" title="Link to this definition"></a></dt>
<dd><p>Computes KID (polynomial MMD) for given sets of features, obtained from Inception net
or any other feature extractor.
Samples must be in range [0, 1].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_x, D)\)</span></p></li>
<li><p><strong>y_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_y, D)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KID score and variance (optional).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MDSILoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">MDSILoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">140.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">55.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">550.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">o</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combination</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/mdsi.html#MDSILoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MDSILoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures Mean Deviation Similarity Index (MDSI) error between the prediction <span class="math notranslate nohighlight">\(x\)</span>
and target <span class="math notranslate nohighlight">\(y\)</span>.
Supports greyscale and colour images with RGB channel order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>c1</strong> – coefficient to calculate gradient similarity. Default: 140.</p></li>
<li><p><strong>c2</strong> – coefficient to calculate gradient similarity. Default: 55.</p></li>
<li><p><strong>c3</strong> – coefficient to calculate chromaticity similarity. Default: 550.</p></li>
<li><p><strong>combination</strong> – mode to combine gradient similarity and chromaticity similarity: <code class="docutils literal notranslate"><span class="pre">'sum'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mult'</span></code>.</p></li>
<li><p><strong>alpha</strong> – coefficient to combine gradient similarity and chromaticity similarity using summation.</p></li>
<li><p><strong>beta</strong> – power to combine gradient similarity with chromaticity similarity using multiplication.</p></li>
<li><p><strong>gamma</strong> – to combine gradient similarity and chromaticity similarity using multiplication.</p></li>
<li><p><strong>rho</strong> – order of the Minkowski distance</p></li>
<li><p><strong>q</strong> – coefficient to adjusts the emphasis of the values in image and MCT</p></li>
<li><p><strong>o</strong> – the power pooling applied on the final value of the deviation</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">MDSILoss</span><span class="p">(</span><span class="n">data_range</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Nafchi, Hossein Ziaei and Shahkolaei, Atena and Hedjam, Rachid and Cheriet, Mohamed (2016).
Mean deviation similarity index: Efficient and reliable full-reference image quality evaluator.
IEEE Ieee Access, 4, 5579–5590.
<a class="reference external" href="https://arxiv.org/pdf/1608.07433.pdf">https://arxiv.org/pdf/1608.07433.pdf</a>
DOI:<cite>10.1109/ACCESS.2016.2604042</cite></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ratio between constants is usually equal <span class="math notranslate nohighlight">\(c_3 = 4c_1 = 10c_2\)</span></p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MDSILoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/mdsi.html#MDSILoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MDSILoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Mean Deviation Similarity Index (MDSI) as a loss function.</p>
<p>Both inputs are supposed to have RGB channels order.
Greyscale images converted to RGB by copying the grey channel 3 times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of MDSI loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both inputs are supposed to have RGB channels order in accordance with the original approach.
Nevertheless, the method supports greyscale images, which are converted to RGB by copying the grey
channel 3 times.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MSID">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">MSID</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rademacher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_laplacian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'empty'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">msid_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'max'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/msid.html#MSID"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MSID" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures MSID score for two batches of images
It’s computed for a whole set of data and uses features from encoder instead of images itself
to decrease computation cost. MSID can compare two data distributions with different
number of samples or different dimensionalities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ts</strong> – Temperature values. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default value <code class="docutils literal notranslate"><span class="pre">torch.logspace(-1,</span> <span class="pre">1,</span> <span class="pre">256)</span></code> is used.</p></li>
<li><p><strong>k</strong> – Number of neighbours for graph construction.</p></li>
<li><p><strong>m</strong> – Lanczos steps in SLQ.</p></li>
<li><p><strong>niters</strong> – Number of starting random vectors for SLQ.</p></li>
<li><p><strong>rademacher</strong> – True to use Rademacher distribution,
False - standard normal for random vectors in Hutchinson.</p></li>
<li><p><strong>normalized_laplacian</strong> – if True, use normalized Laplacian.</p></li>
<li><p><strong>normalize</strong> – <code class="docutils literal notranslate"><span class="pre">'empty'</span></code> for average heat kernel (corresponds to the empty graph normalization of NetLSD),
<code class="docutils literal notranslate"><span class="pre">'complete'</span></code> for the complete, <code class="docutils literal notranslate"><span class="pre">'er'</span></code> for Erdos-Renyi normalization, <code class="docutils literal notranslate"><span class="pre">'none'</span></code> for no normalization</p></li>
<li><p><strong>msid_mode</strong> – <code class="docutils literal notranslate"><span class="pre">'l2'</span></code> to compute the L2 norm of the distance between <cite>msid1</cite> and <cite>msid2</cite>;
<code class="docutils literal notranslate"><span class="pre">'max'</span></code> to find the maximum absolute difference between two descriptors over temperature</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">msid_metric</span> <span class="o">=</span> <span class="n">MSID</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">msid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">msid_metric</span><span class="p">(</span><span class="n">x_feats</span><span class="p">,</span> <span class="n">y_feats</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Tsitsulin, A., Munkhoeva, M., Mottin, D., Karras, P., Bronstein, A., Oseledets, I., &amp; Müller, E. (2019).
The shape of data: Intrinsic distance for data distributions.
<a class="reference external" href="https://arxiv.org/abs/1905.11141">https://arxiv.org/abs/1905.11141</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MSID.compute_metric">
<span class="sig-name descname"><span class="pre">compute_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/msid.html#MSID.compute_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MSID.compute_metric" title="Link to this definition"></a></dt>
<dd><p>Compute MSID score between two sets of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_x, D_x)\)</span></p></li>
<li><p><strong>y_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_y, D_y)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scalar value of the distance between distributions.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MultiScaleGMSDLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">MultiScaleGMSDLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chromatic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">15.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">170</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/gmsd.html#MultiScaleGMSDLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MultiScaleGMSDLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures multi scale Gradient Magnitude Similarity Deviation
between each element in the input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>scale_weights</strong> – Weights for different scales. Can contain any number of floating point values.
By default weights are initialized with values from the paper.</p></li>
<li><p><strong>chromatic</strong> – Flag to use MS-GMSDc algorithm from paper.
It also evaluates chromatic components of the image. Default: True</p></li>
<li><p><strong>beta1</strong> – Algorithm parameter. Weight of chromatic component in the loss.</p></li>
<li><p><strong>beta2</strong> – Algorithm parameter. Small constant, references.</p></li>
<li><p><strong>beta3</strong> – Algorithm parameter. Small constant, references.</p></li>
<li><p><strong>t</strong> – Constant from the reference paper numerical stability of similarity map</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">MultiScaleGMSDLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Bo Zhang et al. Gradient Magnitude Similarity Deviation on Multiple Scales (2017).
<a class="reference external" href="http://www.cse.ust.hk/~psander/docs/gradsim.pdf">http://www.cse.ust.hk/~psander/docs/gradsim.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MultiScaleGMSDLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/gmsd.html#MultiScaleGMSDLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MultiScaleGMSDLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Multi Scale GMSD index as a loss function.
Supports greyscale and colour images with RGB channel order.
The height and width should be at least 2 ** scales + 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of MS-GMSD loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MultiScaleSSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">MultiScaleSSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">11</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/ms_ssim.html#MultiScaleSSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MultiScaleSSIMLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the multi-scale structural similarity index error between
each element in the input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.
The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}MSSIM = \{mssim_1,\dots,mssim_{N \times C}\}, \\
mssim_{l}(x, y) = \frac{(2 \mu_{x,m} \mu_{y,m} + c_1) }
{(\mu_{x,m}^2 +\mu_{y,m}^2 + c_1)} \prod_{j=1}^{m - 1}
\frac{(2 \sigma_{xy,j} + c_2)}{(\sigma_{x,j}^2 +\sigma_{y,j}^2 + c_2)}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the batch size, <cite>C</cite> is the channel size, <cite>m</cite> is the scale level (Default: 5).
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code> (default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}MultiscaleSSIMLoss(x, y) =
\begin{cases}
    \operatorname{mean}(1 - MSSIM), &amp;  \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(1 - MSSIM),  &amp;  \text{if reduction} = \text{'sum'.}
\end{cases}\end{split}\]</div>
<p>For colour images channel order is RGB.
In case of 5D input tensors, complex value is returned as a tensor of size 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – By default, the mean and covariance of a pixel is obtained
by convolution with given filter_size. Must be an odd value.</p></li>
<li><p><strong>kernel_sigma</strong> – Standard deviation for Gaussian kernel.</p></li>
<li><p><strong>k1</strong> – Coefficient related to c1 in the above equation.</p></li>
<li><p><strong>k2</strong> – Coefficient related to c2 in the above equation.</p></li>
<li><p><strong>scale_weights</strong> – Weights for different scales.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, default weights from the paper will be used.
Default weights: (0.0448, 0.2856, 0.3001, 0.2363, 0.1333).</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type: <code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">MultiScaleSSIMLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wang, Z., Simoncelli, E. P., Bovik, A. C. (2003).
Multi-scale Structural Similarity for Image Quality Assessment.
IEEE Asilomar Conference on Signals, Systems and Computers, 37,
<a class="reference external" href="https://ieeexplore.ieee.org/document/1292216">https://ieeexplore.ieee.org/document/1292216</a>
DOI:<cite>10.1109/ACSSC.2003.1292216</cite></p>
<p>Wang, Z., Bovik, A. C., Sheikh, H. R., &amp; Simoncelli, E. P. (2004).
Image quality assessment: From error visibility to structural similarity.
IEEE Transactions on Image Processing, 13, 600-612.
<a class="reference external" href="https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf">https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf</a>,
DOI:<cite>10.1109/TIP.2003.819861</cite></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The size of the image should be at least <code class="docutils literal notranslate"><span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">2</span> <span class="pre">**</span> <span class="pre">(levels</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">+</span> <span class="pre">1</span></code>.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.MultiScaleSSIMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/ms_ssim.html#MultiScaleSSIMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.MultiScaleSSIMLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Multi-scale Structural Similarity (MS-SSIM) index as a loss function.
For colour images channel order is RGB.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> or <span class="math notranslate nohighlight">\((N, C, H, W, 2)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> or <span class="math notranslate nohighlight">\((N, C, H, W, 2)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of MS-SSIM loss to be minimized, i.e. <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">ms_ssim</span></code> in [0, 1] range. In case of 5D tensor,
complex value is returned as a tensor of size 2.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.PR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">PR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nearest_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/pr.html#PR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.PR" title="Link to this definition"></a></dt>
<dd><p>Interface of Improved Precision and Recall.
It’s computed for a whole set of data and uses features from encoder instead of images itself to decrease
computation cost. Precision and Recall can compare two data distributions with different number of samples.
But dimensionalities should match, otherwise it won’t be possible to correctly compute statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>nearest_k</strong> – Nearest neighbor to compute the non-parametric representation. Shape <span class="math notranslate nohighlight">\(1\)</span></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pr_metric</span> <span class="o">=</span> <span class="n">PR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="o">=</span> <span class="n">pr_metric</span><span class="p">(</span><span class="n">x_feats</span><span class="p">,</span> <span class="n">y_feats</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Kynkäänniemi T. et al. (2019).
Improved Precision and Recall Metric for Assessing Generative Models.
Advances in Neural Information Processing Systems,
<a class="reference external" href="https://arxiv.org/abs/1904.06991">https://arxiv.org/abs/1904.06991</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.PR.compute_metric">
<span class="sig-name descname"><span class="pre">compute_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">real_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fake_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/pr.html#PR.compute_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.PR.compute_metric" title="Link to this definition"></a></dt>
<dd><p>Creates non-parametric representations of the manifolds of real and generated data and computes
the precision and recall between them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>real_features</strong> – Samples from data distribution. Shape <span class="math notranslate nohighlight">\((N_x, D)\)</span></p></li>
<li><p><strong>fake_features</strong> – Samples from fake distribution. Shape <span class="math notranslate nohighlight">\((N_x, D)\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Scalar value of the precision of the generated images.</p>
<p>Scalar value of the recall of the generated images.</p>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.PieAPP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">PieAPP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">27</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/pieapp.html#PieAPP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.PieAPP" title="Link to this definition"></a></dt>
<dd><p>Implementation of Perceptual Image-Error Assessment through Pairwise Preference.</p>
<p>Expects input to be in range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">data_range]</span></code> with no normalization and RGB channel order.
Input images are cropped into smaller patches. Score for each individual image is mean of it’s patch scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>stride</strong> – Step between cropped patches. Smaller values lead to better quality,
but cause higher memory consumption. Default: 27 (<cite>sparse</cite> sampling in original implementation)</p></li>
<li><p><strong>enable_grad</strong> – Flag to compute gradients. Useful when PieAPP used as a loss. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">PieAPP</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Ekta Prashnani, Hong Cai, Yasamin Mostofi, Pradeep Sen (2018).
PieAPP: Perceptual Image-Error Assessment through Pairwise Preference
<a class="reference external" href="https://arxiv.org/abs/1806.02067">https://arxiv.org/abs/1806.02067</a></p>
<p><a class="reference external" href="https://github.com/prashnani/PerceptualImageError">https://github.com/prashnani/PerceptualImageError</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.PieAPP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/pieapp.html#PieAPP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.PieAPP.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of PieAPP  between feature representations of prediction <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span> tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Perceptual Image-Error Assessment through Pairwise Preference</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.PieAPP.get_features">
<span class="sig-name descname"><span class="pre">get_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/piq/pieapp.html#PieAPP.get_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.PieAPP.get_features" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of features extracted from intermediate layers weights</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.SRSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">SRSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chromatic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaussian_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/srsim.html#SRSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.SRSIMLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the SR-SIM or SR-SIMc for input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>In order to be considered as a loss, value <cite>1 - clip(SR-SIM, min=0, max=1)</cite> is returned. If you need SR-SIM value,
use function <cite>srsim</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – The difference between the maximum and minimum of the pixel value,
i.e., if for image x it holds min(x) = 0 and max(x) = 1, then data_range = 1.
The pixel value interval of both input and output should remain the same.</p></li>
<li><p><strong>chromatic</strong> – Flag to compute SRSIMc, which also takes into account chromatic components</p></li>
<li><p><strong>scale</strong> – Resizing factor used in saliency map computation</p></li>
<li><p><strong>kernel_size</strong> – Kernel size of average blur filter used in saliency map computation</p></li>
<li><p><strong>sigma</strong> – Sigma of gaussian filter applied on saliency map</p></li>
<li><p><strong>gaussian_size</strong> – Size of gaussian filter applied on saliency map</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: Required to be 2D (H, W), 3D (C, H, W) or 4D (N, C, H, W). RGB channel order for colour images.</p></li>
<li><p>Target: Required to be 2D (H, W), 3D (C, H, W) or 4D (N, C, H, W). RGB channel order for colour images.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">SRSIMLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p><a class="reference external" href="https://sse.tongji.edu.cn/linzhang/ICIP12/ICIP-SR-SIM.pdf">https://sse.tongji.edu.cn/linzhang/ICIP12/ICIP-SR-SIM.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.SRSIMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/srsim.html#SRSIMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.SRSIMLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of SR-SIM as a loss function.
:param prediction: Tensor of prediction of the network.
:param target: Reference tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Value of SR-SIM loss to be minimized. 0 &lt;= SR-SIM &lt;= 1.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.SSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">SSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">11</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/ssim.html#SSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.SSIMLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the structural similarity index error between
each element in the input <span class="math notranslate nohighlight">\(x\)</span> and target <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>To match performance with skimage and tensorflow set <code class="docutils literal notranslate"><span class="pre">'downsample'</span> <span class="pre">=</span> <span class="pre">True</span></code>.</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}SSIM = \{ssim_1,\dots,ssim_{N \times C}\}\\
ssim_{l}(x, y) = \frac{(2 \mu_x \mu_y + c_1) (2 \sigma_{xy} + c_2)}
{(\mu_x^2 +\mu_y^2 + c_1)(\sigma_x^2 +\sigma_y^2 + c_2)},\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the batch size, <cite>C</cite> is the channel size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}SSIMLoss(x, y) =
\begin{cases}
    \operatorname{mean}(1 - SSIM), &amp;  \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(1 - SSIM),  &amp;  \text{if reduction} = \text{'sum'.}
\end{cases}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are tensors of arbitrary shapes with a total
of <span class="math notranslate nohighlight">\(n\)</span> elements each.</p>
<p>The sum operation still operates over all the elements, and divides by <span class="math notranslate nohighlight">\(n\)</span>.
The division by <span class="math notranslate nohighlight">\(n\)</span> can be avoided if one sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.
In case of 5D input tensors, complex value is returned as a tensor of size 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – By default, the mean and covariance of a pixel is obtained
by convolution with given filter_size.</p></li>
<li><p><strong>kernel_sigma</strong> – Standard deviation for Gaussian kernel.</p></li>
<li><p><strong>k1</strong> – Coefficient related to c1 in the above equation.</p></li>
<li><p><strong>k2</strong> – Coefficient related to c2 in the above equation.</p></li>
<li><p><strong>downsample</strong> – Perform average pool before SSIM computation. Default: True</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">SSIMLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wang, Z., Bovik, A. C., Sheikh, H. R., &amp; Simoncelli, E. P. (2004).
Image quality assessment: From error visibility to structural similarity.
IEEE Transactions on Image Processing, 13, 600-612.
<a class="reference external" href="https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf">https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf</a>,
DOI:<cite>10.1109/TIP.2003.819861</cite></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.SSIMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/ssim.html#SSIMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.SSIMLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Structural Similarity (SSIM) index as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> or <span class="math notranslate nohighlight">\((N, C, H, W, 2)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> or <span class="math notranslate nohighlight">\((N, C, H, W, 2)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of SSIM loss to be minimized, i.e <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">ssim</span></code> in [0, 1] range. In case of 5D input tensors,
complex value is returned as a tensor of size 2.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.StyleLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">StyleLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_extractor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Module</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'vgg16'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">('relu3_3',)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[1.0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_pooling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_layers_weights_mismatch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/perceptual.html#StyleLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.StyleLoss" title="Link to this definition"></a></dt>
<dd><p>Creates Style loss that can be used for image style transfer or as a measure in
image to image tasks. Computes distance between Gram matrices of feature maps.
Uses pretrained VGG models from torchvision.</p>
<p>By default expects input to be in range [0, 1], which is then normalized by ImageNet statistics into range [-1, 1].
If no normalisation is required, change <cite>mean</cite> and <cite>std</cite> values accordingly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_extractor</strong> – Model to extract features or model name: <code class="docutils literal notranslate"><span class="pre">'vgg16'</span></code> | <code class="docutils literal notranslate"><span class="pre">'vgg19'</span></code>.</p></li>
<li><p><strong>layers</strong> – List of strings with layer names. Default: <code class="docutils literal notranslate"><span class="pre">'relu3_3'</span></code></p></li>
<li><p><strong>weights</strong> – List of float weight to balance different layers</p></li>
<li><p><strong>replace_pooling</strong> – Flag to replace MaxPooling layer with AveragePooling. See references for details.</p></li>
<li><p><strong>distance</strong> – Method to compute distance between features: <code class="docutils literal notranslate"><span class="pre">'mse'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mae'</span></code>.</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>mean</strong> – List of float values used for data standardization. Default: ImageNet mean.
If there is no need to normalize data, use [0., 0., 0.].</p></li>
<li><p><strong>std</strong> – List of float values used for data standardization. Default: ImageNet std.
If there is no need to normalize data, use [1., 1., 1.].</p></li>
<li><p><strong>normalize_features</strong> – If true, unit-normalize each feature in channel dimension before scaling
and computing distance. See references for details.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">StyleLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Gatys, Leon and Ecker, Alexander and Bethge, Matthias (2016).
A Neural Algorithm of Artistic Style
Association for Research in Vision and Ophthalmology (ARVO)
<a class="reference external" href="https://arxiv.org/abs/1508.06576">https://arxiv.org/abs/1508.06576</a></p>
<p>Zhang, Richard and Isola, Phillip and Efros, et al. (2018)
The Unreasonable Effectiveness of Deep Features as a Perceptual Metric
IEEE/CVF Conference on Computer Vision and Pattern Recognition
<a class="reference external" href="https://arxiv.org/abs/1801.03924">https://arxiv.org/abs/1801.03924</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.StyleLoss.compute_distance">
<span class="sig-name descname"><span class="pre">compute_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/perceptual.html#StyleLoss.compute_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.StyleLoss.compute_distance" title="Link to this definition"></a></dt>
<dd><p>Take L2 or L1 distance between Gram matrices of feature maps depending on <code class="docutils literal notranslate"><span class="pre">distance</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_features</strong> – Features of the input tensor.</p></li>
<li><p><strong>y_features</strong> – Features of the target tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Distance between Gram matrices</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.StyleLoss.gram_matrix">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/perceptual.html#StyleLoss.gram_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.StyleLoss.gram_matrix" title="Link to this definition"></a></dt>
<dd><p>Compute Gram matrix for batch of features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gram matrix for given input</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.TVLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">TVLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/tv.html#TVLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.TVLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the total variation of the
the given input <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">norm_type</span></code> set to <code class="docutils literal notranslate"><span class="pre">'l2'</span></code> the loss can be described as:</p>
<div class="math notranslate nohighlight">
\[TV(x) = \sum_{N}\sqrt{\sum_{H, W, C}(|x_{:, :, i+1, j} - x_{:, :, i, j}|^2 +
|x_{:, :, i, j+1} - x_{:, :, i, j}|^2)}\]</div>
<p>Else if <code class="xref py py-attr docutils literal notranslate"><span class="pre">norm_type</span></code> set to <code class="docutils literal notranslate"><span class="pre">'l1'</span></code>:</p>
<div class="math notranslate nohighlight">
\[TV(x) = \sum_{N}\sum_{H, W, C}(|x_{:, :, i+1, j} - x_{:, :, i, j}| +
|x_{:, :, i, j+1} - x_{:, :, i, j}|)\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the batch size, <cite>C</cite> is the channel size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_type</strong> – one of <code class="docutils literal notranslate"><span class="pre">'l1'</span></code> | <code class="docutils literal notranslate"><span class="pre">'l2'</span></code> | <code class="docutils literal notranslate"><span class="pre">'l2_squared'</span></code></p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">TVLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p><a class="reference external" href="https://www.wikiwand.com/en/Total_variation_denoising">https://www.wikiwand.com/en/Total_variation_denoising</a></p>
<p><a class="reference external" href="https://remi.flamary.com/demos/proxtv.html">https://remi.flamary.com/demos/proxtv.html</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.TVLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/tv.html#TVLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.TVLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Total Variation (TV) index as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of TV loss to be minimized.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.VIFLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">VIFLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sigma_n_sq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/vif.html#VIFLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.VIFLoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures the Visual Information Fidelity loss
between predicted (x) and target (y) image. In order to be considered as a loss,
value <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">clip(VIF,</span> <span class="pre">min=0,</span> <span class="pre">max=1)</span></code> is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma_n_sq</strong> – HVS model parameter (variance of the visual noise).</p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">VIFLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>H. R. Sheikh and A. C. Bovik, “Image information and visual quality,”
IEEE Transactions on Image Processing, vol. 15, no. 2, pp. 430-444, Feb. 2006
<a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/1576816/">https://ieeexplore.ieee.org/abstract/document/1576816/</a>
DOI: 10.1109/TIP.2005.859378.</p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.VIFLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/vif.html#VIFLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.VIFLoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of Visual Information Fidelity (VIF) index as a loss function.
Colour images are expected to have RGB channel order.
Order of inputs is important! First tensor must contain distorted images, second reference images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of VIF loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.VSILoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">VSILoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.27</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">386.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c3</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">130.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">omega_0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.021</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_f</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.34</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_d</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">145.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_c</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/vsi.html#VSILoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.VSILoss" title="Link to this definition"></a></dt>
<dd><p>Creates a criterion that measures Visual Saliency-induced Index error between
each element in the input and target.</p>
<p>The sum operation still operates over all the elements, and divides by <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>The division by <span class="math notranslate nohighlight">\(n\)</span> can be avoided if one sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>c1</strong> – coefficient to calculate saliency component of VSI</p></li>
<li><p><strong>c2</strong> – coefficient to calculate gradient component of VSI</p></li>
<li><p><strong>c3</strong> – coefficient to calculate color component of VSI</p></li>
<li><p><strong>alpha</strong> – power for gradient component of VSI</p></li>
<li><p><strong>beta</strong> – power for color component of VSI</p></li>
<li><p><strong>omega_0</strong> – coefficient to get log Gabor filter at SDSP</p></li>
<li><p><strong>sigma_f</strong> – coefficient to get log Gabor filter at SDSP</p></li>
<li><p><strong>sigma_d</strong> – coefficient to get SDSP</p></li>
<li><p><strong>sigma_c</strong> – coefficient to get SDSP</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">VSILoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>L. Zhang, Y. Shen and H. Li, “VSI: A Visual Saliency-Induced Index for Perceptual Image Quality Assessment,”
IEEE Transactions on Image Processing, vol. 23, no. 10, pp. 4270-4281, Oct. 2014, doi: 10.1109/TIP.2014.2346028
<a class="reference external" href="https://ieeexplore.ieee.org/document/6873260">https://ieeexplore.ieee.org/document/6873260</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.VSILoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/piq/vsi.html#VSILoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.VSILoss.forward" title="Link to this definition"></a></dt>
<dd><p>Computation of VSI as a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Value of VSI loss to be minimized in [0, 1] range.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both inputs are supposed to have RGB channels order in accordance with the original approach.
Nevertheless, the method supports greyscale images, which they are converted to RGB by copying the grey
channel 3 times.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.total_variation">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">total_variation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l2'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/tv.html#total_variation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.total_variation" title="Link to this definition"></a></dt>
<dd><p>Compute Total Variation metric</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>norm_type</strong> – <code class="docutils literal notranslate"><span class="pre">'l1'</span></code> | <code class="docutils literal notranslate"><span class="pre">'l2'</span></code> | <code class="docutils literal notranslate"><span class="pre">'l2_squared'</span></code>,
defines which type of norm to implement, isotropic  or anisotropic.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Total variation of a given tensor</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://www.wikiwand.com/en/Total_variation_denoising">https://www.wikiwand.com/en/Total_variation_denoising</a></p>
<p><a class="reference external" href="https://remi.flamary.com/demos/proxtv.html">https://remi.flamary.com/demos/proxtv.html</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="olimp.evaluation.loss.piq.vif_p">
<span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.piq.</span></span><span class="sig-name descname"><span class="pre">vif_p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_n_sq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/piq/vif.html#vif_p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.piq.vif_p" title="Link to this definition"></a></dt>
<dd><p>Compute Visiual Information Fidelity in <strong>pixel</strong> domain for a batch of images.
This metric isn’t symmetric, so make sure to place arguments in correct order.
Both inputs supposed to have RGB channels order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – An input tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>y</strong> – A target tensor. Shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>sigma_n_sq</strong> – HVS model parameter (variance of the visual noise).</p></li>
<li><p><strong>data_range</strong> – Maximum value range of images (usually 1.0 or 255).</p></li>
<li><p><strong>reduction</strong> – Specifies the reduction type:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. Default:<code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>VIF Index of similarity between two images. Usually in [0, 1] interval.
Can be bigger than 1 for predicted <span class="math notranslate nohighlight">\(x\)</span> images with higher contrast than original one.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>H. R. Sheikh and A. C. Bovik, “Image information and visual quality,”
IEEE Transactions on Image Processing, vol. 15, no. 2, pp. 430-444, Feb. 2006
<a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/1576816/">https://ieeexplore.ieee.org/abstract/document/1576816/</a>
DOI: 10.1109/TIP.2005.859378.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In original paper this method was used for bands in discrete wavelet decomposition.
Later on authors released code to compute VIF approximation in pixel domain.
See <a class="reference external" href="https://live.ece.utexas.edu/research/Quality/VIF.htm">https://live.ece.utexas.edu/research/Quality/VIF.htm</a> for details.</p>
</div>
</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.psnr">
<span id="psnr"></span><h2>psnr<a class="headerlink" href="#module-olimp.evaluation.loss.psnr" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.psnr.PSNR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.psnr.</span></span><span class="sig-name descname"><span class="pre">PSNR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mse_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#olimp.evaluation.loss.mse.MSE" title="olimp.evaluation.loss.mse.MSE"><span class="pre">MSE</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">MSE()</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/psnr.html#PSNR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.psnr.PSNR" title="Link to this definition"></a></dt>
<dd><p>Peak Signal-to-Noise Ratio (PSNR) metric implemented as a PyTorch module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mse_metric</strong> (<em>Module</em>) – MSE metric class instance.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.psnr.PSNR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/psnr.html#PSNR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.psnr.PSNR.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the Peak Signal-to-Noise Ratio (PSNR) between two tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – First input tensor.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Second input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed PSNR value. Returns <cite>inf</cite> if MSE is zero.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.rms">
<span id="rms"></span><h2>rms<a class="headerlink" href="#module-olimp.evaluation.loss.rms" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.rms.RMS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.rms.</span></span><span class="sig-name descname"><span class="pre">RMS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">color_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'lab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'prolab'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pixel_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/rms.html#RMS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.rms.RMS" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-olimp.evaluation.loss.s_oklab">
<span id="s-oklab"></span><h2>s_oklab<a class="headerlink" href="#module-olimp.evaluation.loss.s_oklab" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.s_oklab.SOkLab">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.s_oklab.</span></span><span class="sig-name descname"><span class="pre">SOkLab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dpi</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_inch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/s_oklab.html#SOkLab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.s_oklab.SOkLab" title="Link to this definition"></a></dt>
<dd><p>Code is based on:
<a class="reference external" href="https://github.com/iitpvisionlab/vsl_ial/blob/main/vsl_ial/image_metric.py">https://github.com/iitpvisionlab/vsl_ial/blob/main/vsl_ial/image_metric.py</a></p>
</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.ssim">
<span id="ssim"></span><h2>ssim<a class="headerlink" href="#module-olimp.evaluation.loss.ssim" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.ssim.ContrastLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.ssim.</span></span><span class="sig-name descname"><span class="pre">ContrastLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/ssim.html#ContrastLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.ssim.ContrastLoss" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.ssim.SSIMLoss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.ssim.</span></span><span class="sig-name descname"><span class="pre">SSIMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">11</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/ssim.html#SSIMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.ssim.SSIMLoss" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-olimp.evaluation.loss.stress">
<span id="stress"></span><h2>stress<a class="headerlink" href="#module-olimp.evaluation.loss.stress" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="olimp.evaluation.loss.stress.STRESS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">olimp.evaluation.loss.stress.</span></span><span class="sig-name descname"><span class="pre">STRESS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">invert</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/stress.html#STRESS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.stress.STRESS" title="Link to this definition"></a></dt>
<dd><p>Computes the Stress or 1 - Stress metric between two tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>invert</strong> (<em>bool</em>) – If True, computes <cite>1 - Stress</cite>. Default is False.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="olimp.evaluation.loss.stress.STRESS.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../../_modules/olimp/evaluation/loss/stress.html#STRESS.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#olimp.evaluation.loss.stress.STRESS.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the Stress metric (or 1 - Stress if invert is True).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – First input tensor.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Second input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed metric value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-olimp.evaluation.loss.lpips">
<span id="lpips"></span><h2>lpips<a class="headerlink" href="#module-olimp.evaluation.loss.lpips" title="Link to this heading"></a></h2>
<p>Perceptual Similarity Metric</p>
<p><a class="reference external" href="https://github.com/richzhang/PerceptualSimilarity">https://github.com/richzhang/PerceptualSimilarity</a></p>
<p>Usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">olimp.evaluation.loss.lpips</span> <span class="kn">import</span> <span class="n">LPIPS</span>

<span class="c1"># best forward scores</span>
<span class="n">loss_fn_alex</span> <span class="o">=</span> <span class="n">LPIPS</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="s1">&#39;alex&#39;</span><span class="p">)</span>

<span class="c1"># closer to &quot;traditional&quot; perceptual loss, when used for optimization</span>
<span class="n">loss_fn_vgg</span> <span class="o">=</span> <span class="n">LPIPS</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="s1">&#39;vgg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../dataset.html" class="btn btn-neutral float-left" title="Dataset" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../processing.html" class="btn btn-neutral float-right" title="Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, PyOlimp authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>